{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CoolAvatars",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "xEOvn3VL0p3p",
        "outputId": "9298661d-2151-45f5-cb77-095802422cb8"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def get_image(path, img_transform , size=(720,1280)):\n",
        "  image = Image.open(path)\n",
        "  image = image.resize(size, Image.LANCZOS)\n",
        "  image = img_transform(image).unsqueeze(0)  # h,w -> 1,h,w\n",
        "  return image.to(device)\n",
        "\n",
        "def get_gram(m): # m => batch size , C , H , W\n",
        "  b_size , c, h, w = m.size()\n",
        "  m = m.view(c, h*w)\n",
        "  m = torch.mm(m, m.t())\n",
        "  return m\n",
        "\n",
        "def denorm_image(inp):\n",
        "  inp = inp.numpy().transpose((1,2,0)) # C, H, W -> H, W, C\n",
        "  mean = np.array([0.485 , 0.456 , 0.406])\n",
        "  std = np.array([0.229 , 0.224 , 0.225])\n",
        "  inp = inp*std + mean   # doing the reverse of (x-mean)/sigma\n",
        "  inp = inp.clip(inp,0,1)\n",
        "  return inp\n",
        "\n",
        "class FeatureExtractor(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(FeatureExtractor,self).__init__()\n",
        "    self.selected_layers = [3,8,15,22]  # all the relu activation layers are chosen\n",
        "    self.vgg = models.vgg16(pretrained=True).features\n",
        "  \n",
        "  def forward(self, x):\n",
        "    layer_feats = []\n",
        "    for layer_num,layer in self.vgg._modules.items():\n",
        "      x = layer(x)\n",
        "      if int(layer_num) in self.selected_layers:\n",
        "        layer_feats.append(x)\n",
        "    return layer_feats\n",
        "\n",
        "\n",
        "\n",
        "img_transform = transforms.Compose(\n",
        "                                    [transforms.ToTensor(),\n",
        "                                    transforms.Normalize(mean=(0.485 , 0.456 , 0.406) , std=(0.229 , 0.224 , 0.225))\n",
        "                                    ]\n",
        "                                   )\n",
        "content_image = get_image('/content/drive/MyDrive/NeuralStyleTransfer/content.jpg', img_transform)\n",
        "style_image = get_image('/content/drive/MyDrive/NeuralStyleTransfer/style.jpg', img_transform)\n",
        "generated_image = content_image.clone()  \n",
        "generated_image.requires_grad = True\n",
        "opt = torch.optim.Adam([generated_image] , lr = 0.003 , betas = [0.5, 0.999])\n",
        "encoder = FeatureExtractor().to(device)\n",
        "for p in encoder.parameters():\n",
        "  p.requires_grad = False\n",
        "style_weight = 100\n",
        "cont_weight = 1\n",
        "for epoch in range(5000):\n",
        "  content_features = encoder(content_image)\n",
        "  style_features = encoder(style_image)\n",
        "  generated_features = encoder(generated_image)\n",
        "  cont_loss = torch.mean((content_features[-1] - generated_features[-1])**2)\n",
        "  style_loss = 0\n",
        "  for gf, sf in zip(generated_features,style_features):\n",
        "    _,c,h,w = gf.size()\n",
        "    gram_gf = get_gram(gf)\n",
        "    gram_sf = get_gram(sf)\n",
        "    style_loss += torch.mean((gram_gf - gram_sf)**2)/(c*h*w)\n",
        "  loss = cont_weight*cont_loss + style_weight*style_loss\n",
        "  opt.zero_grad()\n",
        "  loss.backward()\n",
        "  opt.step()\n",
        "  if epoch%100 == 0:\n",
        "    print(f\"Epoch is {epoch} , Content Loss is {cont_loss} , Style Loss is {style_loss} , Total Loss is {loss}\")\n",
        "    print(\"==========================================================================================================\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a61adb3f804144868665ff019edfe123",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/528M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch is 0 , Content Loss is 0.0 , Style Loss is 5281.4091796875 , Total Loss is 528140.9375\n",
            "==========================================================================================================\n",
            "Epoch is 100 , Content Loss is 0.994583249092102 , Style Loss is 971.04736328125 , Total Loss is 97105.7265625\n",
            "==========================================================================================================\n",
            "Epoch is 200 , Content Loss is 1.210949182510376 , Style Loss is 450.52630615234375 , Total Loss is 45053.83984375\n",
            "==========================================================================================================\n",
            "Epoch is 300 , Content Loss is 1.334060788154602 , Style Loss is 290.0861511230469 , Total Loss is 29009.94921875\n",
            "==========================================================================================================\n",
            "Epoch is 400 , Content Loss is 1.4217565059661865 , Style Loss is 202.24827575683594 , Total Loss is 20226.25\n",
            "==========================================================================================================\n",
            "Epoch is 500 , Content Loss is 1.492169737815857 , Style Loss is 152.50277709960938 , Total Loss is 15251.76953125\n",
            "==========================================================================================================\n",
            "Epoch is 600 , Content Loss is 1.5491524934768677 , Style Loss is 122.091064453125 , Total Loss is 12210.6552734375\n",
            "==========================================================================================================\n",
            "Epoch is 700 , Content Loss is 1.5977041721343994 , Style Loss is 101.45652770996094 , Total Loss is 10147.25\n",
            "==========================================================================================================\n",
            "Epoch is 800 , Content Loss is 1.6428710222244263 , Style Loss is 86.38429260253906 , Total Loss is 8640.072265625\n",
            "==========================================================================================================\n",
            "Epoch is 900 , Content Loss is 1.6823447942733765 , Style Loss is 74.84224700927734 , Total Loss is 7485.90673828125\n",
            "==========================================================================================================\n",
            "Epoch is 1000 , Content Loss is 1.716742992401123 , Style Loss is 65.73894500732422 , Total Loss is 6575.611328125\n",
            "==========================================================================================================\n",
            "Epoch is 1100 , Content Loss is 1.7453303337097168 , Style Loss is 58.33928680419922 , Total Loss is 5835.673828125\n",
            "==========================================================================================================\n",
            "Epoch is 1200 , Content Loss is 1.7698861360549927 , Style Loss is 52.20426940917969 , Total Loss is 5222.19677734375\n",
            "==========================================================================================================\n",
            "Epoch is 1300 , Content Loss is 1.7919951677322388 , Style Loss is 46.99162292480469 , Total Loss is 4700.9541015625\n",
            "==========================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "YOzrNH6D-AYb",
        "outputId": "a82c0ae6-96e9-4ccd-ee2d-dc48212b004e"
      },
      "source": [
        "inp = generated_image.detach().cpu().squeeze()\n",
        "inp = denorm_image(inp)\n",
        "plt.imshow(inp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-fe218281de26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerated_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdenorm_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-c8eece562ba6>\u001b[0m in \u001b[0;36mdenorm_image\u001b[0;34m(inp)\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.229\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0.224\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0.225\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstd\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmean\u001b[0m   \u001b[0;31m# doing the reverse of (x-mean)/sigma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m   \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_clip\u001b[0;34m(a, min, max, out, casting, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         return _clip_dep_invoke_with_casting(\n\u001b[0;32m--> 141\u001b[0;31m             um.clip, a, min, max, out=out, casting=casting, **kwargs)\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_clip_dep_invoke_with_casting\u001b[0;34m(ufunc, out, casting, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# try to deal with broken casting rules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_exceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_UFuncOutputCastingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# Numpy 1.17.0, 2019-02-24\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: return arrays must be of ArrayType"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-DugC_WlbGQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}